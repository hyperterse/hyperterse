---
title: Caching
description: In-memory query result caching, cache key derivation, TTL, and override behavior.
icon: "bolt"
---

Hyperterse includes an executor-level in-memory cache. The cache stores query results keyed by the combination of query name and substituted statement, eliminating redundant connector execution for identical requests.

Caching applies to DB-backed routes only. Script-backed routes (handler-only) bypass the cache.

## Cache key derivation

Each entry is identified by:

```
cache_key = hash(query_name + substituted_statement)
```

The same query with different input values produces different cache entries. Identical inputs for the same query produce a cache hit.


## Configuration

Caching is controlled at two levels: global defaults in the root config and per-route overrides.

### Global defaults

Set default caching in `.hyperterse`:

```yaml
server:
  queries:
    cache:
      enabled: true
      ttl: 60
```

| Field | Type | Default | Description |
|---|---|---|---|
| `enabled` | boolean | `false` | Whether caching is active for all queries. |
| `ttl` | integer | `120` | Time-to-live in seconds. |

### Per-route override

```yaml
cache:
  enabled: true
  ttl: 30
```

```yaml
cache:
  enabled: false
```

### Precedence

1. Route-level config (highest priority).
2. Global server config.
3. Framework defaults (`enabled: false`, `ttl: 120`).


## Behavior

The cache operates as a read-through layer in front of connectors and handler scripts.

### On execution

1. Before connector execution, the executor checks the cache using the derived key.
2. **Hit:** cached result returned immediately; connector is not called.
3. **Miss:** connector executes; result stored with configured TTL before being returned.

### Eviction

- **TTL-based.** Entries expire after their configured TTL.
- **Capacity-based.** The cache enforces memory bounds (128 MiB default). When approaching capacity, least-recently-used entries are evicted.

### No explicit invalidation

There is no API for manual cache invalidation. Entries are evicted only by TTL or capacity pressure. For immediate invalidation, disable caching on affected routes and manage cache externally (e.g., through a Redis adapter with handler logic).


## Characteristics

| Property | Value |
|---|---|
| Scope | Process-local. Not shared between instances. |
| Storage | In-memory. No persistence across restarts. |
| Thread safety | Concurrent-safe. Reads and writes do not block execution. |
| Serialization | Results are cloned on store and retrieval to prevent mutation. |
| Distributed | None. Each instance maintains its own cache. |


## When to enable caching

**Enable for:**
- Read-heavy tools with stable data (reference tables, configuration lookups).
- Expensive queries where staleness within the TTL window is acceptable.
- High-frequency tools where connector load reduction matters.

**Disable for:**
- Write operations or tools that must return real-time data.
- Highly variable inputs where cache fill exceeds hit rate.
- Tools where result freshness is critical for correctness.


## Monitoring

Cache hit/miss status is included in OpenTelemetry trace spans when observability is configured. Monitor hit ratio to evaluate whether TTL values are effective for your workload.
